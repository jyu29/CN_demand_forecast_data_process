buckets:
  clean: fcst-clean-dev
  refined: fcst-refined-demand-forecast-dev
paths:
  clean_datalake: datalake/
  refined_global: global/
Tables:
  transactions: "fcst_clean_dev.f_transaction_detail"
  deliveries: "fcst_clean_dev.f_delivery_detail"
  stocks_pict: "fcst_clean_dev.f_stock_picture"
functional_parameters:
  first_historical_week: 201507
  first_backtesting_cutoff: 201924
  lifestage_data_first_hist_week: 201918
  max_nb_soldout_weeks_for_hist: 4
  list_puch_org:
  - Z001
  - Z002
  - Z003
  - Z004
  - Z005
  - Z006
  - Z008
  - Z011
  - Z012
  - Z013
  - Z017
  - Z019
  - Z022
  - Z025
  - Z026
  - Z027
  - Z028
  - Z042
  - Z060
  - Z061
  - Z065
  - Z066
  - Z078
  - Z091
  - Z093
  - Z094
  - Z095
  - Z096
  - Z098
  - Z101
  - Z102
  - Z104
  - Z105
  - Z106
  - Z107
  - Z112
  - Z115
technical_parameters:
    spark_conf:
        spark.yarn.isPython: "true"
        spark.serializer: "org.apache.spark.serializer.KryoSerializer"
        spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version: 2
        spark.maximizeResourceAllocation: "false"
        spark.dynamicAllocation.enabled: "false"
        spark.driver.cores: 5
        spark.driver.memory: "38g"
        spark.executor.cores: 5
        spark.executor.memory: "38g"
        spark.executor.memoryOverhead: "4g"
        spark.executor.instances: 40
        spark.default.parallelism: 200
        spark.executor.extraJavaOptions: "-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled -XX:OnOutOfMemoryError='kill -9 %p'"
        spark.driver.extraJavaOptions: "-XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled -XX:OnOutOfMemoryError='kill -9 %p'"
        spark.yarn.am.cores: 5
        spark.yarn.am.memory: "38g"
        spark.yarn.am.memoryOverhead: "4g"
        hive.exec.dynamic.partition.mode: nonstrict
        spark.sql.sources.partitionOverwriteMode: dynamic
